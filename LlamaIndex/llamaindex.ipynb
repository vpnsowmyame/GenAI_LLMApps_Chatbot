{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4b8964-2ceb-4aa7-aa50-8f2934c017c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8faf7ee-579e-45e2-b22c-4c5ebf7e2d98",
   "metadata": {},
   "source": [
    "## Load private document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb9cd4d-173b-4f4a-a992-8a770c741d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Win 11\\Desktop\\Bootcamp\\LlamaIndex\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0238d1-3bcf-4ded-a769-98d8d93729ef",
   "metadata": {},
   "source": [
    "## Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63975112-0f22-4edd-8c7b-1b4406f8e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 18:42:45,399 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159feeb-7eb4-4911-bbf1-714de67dfe69",
   "metadata": {},
   "source": [
    "## Ask questions to private document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ede51e4-1aec-4a70-9007-7a15b4e6a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 18:42:46,118 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-09 18:42:50,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the importance of creating something people want and not focusing solely on making money in the early stages of a startup. It explores the idea that behaving like a charity can lead to success, using examples like Craigslist and Google. Benevolence is highlighted as a key factor in startup success, improving morale, attracting help from others, and fostering decisiveness. The article emphasizes the value of helping people, building a loyal user base, and the resilience that comes from a sense of mission. Ultimately, being good can lead to long-term success and sustainability in the startup world.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"summarize the article in 100 words\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c19db6-15c5-497a-b018-9c3a3cf12511",
   "metadata": {},
   "source": [
    "## See under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215fa5e0-ee57-48fa-a343-c9662065709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     stream=sys.stdout, \n",
    "#     level=logging.DEBUG\n",
    "# )\n",
    "\n",
    "# logging.getLogger().addHandler(\n",
    "#     logging.StreamHandler(stream=sys.stdout)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c62d2e-4ebc-473a-b215-8d719e87fe3e",
   "metadata": {},
   "source": [
    "## Save the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0043ba-f669-4c0f-b67f-1415da83c491",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory 000-data does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# check if storage already exists\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m\"\u001b[39m\u001b[33m./storage\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# load the documents and create the index\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     documents = \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m000-data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.load_data()\n\u001b[32m      7\u001b[39m     index = VectorStoreIndex.from_documents(documents)\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# store it for later\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Win 11\\Desktop\\Bootcamp\\LlamaIndex\\.venv\\Lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:295\u001b[39m, in \u001b[36mSimpleDirectoryReader.__init__\u001b[39m\u001b[34m(self, input_dir, input_files, exclude, exclude_hidden, exclude_empty, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_dir:\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fs.isdir(input_dir):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_dir = _Path(input_dir)\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m.exclude = exclude\n",
      "\u001b[31mValueError\u001b[39m: Directory 000-data does not exist."
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(\"./storage\"):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist()\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"According to the author, what is good?\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c257e6-0fac-4a32-b1ac-b78338d3a929",
   "metadata": {},
   "source": [
    "## Customization options\n",
    "* parse into smaller chunks\n",
    "* use a different vector store\n",
    "* retrieve more context when I query\n",
    "* use a different LLM\n",
    "* use a different response mode\n",
    "* stream the response back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f150c-7df3-48f9-98fa-b8bd55f696c8",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "* QA\n",
    "* Chatbot\n",
    "* Agent\n",
    "* Structured Data Extraction\n",
    "* Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e50-31b8-45fe-af63-311876d79641",
   "metadata": {},
   "source": [
    "## Optimizing\n",
    "* Advanced Retrieval Strategies\n",
    "* Evaluation\n",
    "* Building performant RAG applications for production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a8a462-4952-48cc-84cb-864841cecbc8",
   "metadata": {},
   "source": [
    "## Other\n",
    "* LlamaPacks and Create-llama = LangChain templates\n",
    "* Very recent, still in beta\n",
    "* Very interesting: create-llama allows you to create a Vercel app!\n",
    "* Very interesting: open-source end-to-end project (SEC Insights)\n",
    "    * llamaindex + react/nextjs (vercel) + fastAPI + render + AWS\n",
    "    * environment setup: localStack + docker\n",
    "    * monitoring: sentry\n",
    "    * load testing: loader.io\n",
    "    * [web](https://www.secinsights.ai/)\n",
    "    * [code](https://github.com/run-llama/sec-insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59ffe0-ded8-41ef-9c1b-3d4af53215bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
